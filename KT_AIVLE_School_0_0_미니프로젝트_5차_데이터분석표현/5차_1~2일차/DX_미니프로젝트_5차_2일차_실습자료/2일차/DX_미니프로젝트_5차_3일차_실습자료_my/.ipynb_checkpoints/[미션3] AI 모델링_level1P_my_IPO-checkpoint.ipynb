{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2fd1695a-8439-4a35-84c8-9970e11b779f",
   "metadata": {},
   "source": [
    "# AIVLE스쿨 4기 DX트랙 5차 미니프로젝트 \n",
    "## [미션#3] 중증질환 예측 모델링"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38396e52-004b-48b5-95cb-8a29e36130ef",
   "metadata": {},
   "source": [
    "[미션] \n",
    " * Target : 중증질환 (뇌경색, 뇌출혈, 복부손상, 심근경색)\n",
    " * 데이터 분석 결과를 바탕으로 Target에 영향을 주는 Feature 전처리 (함수 정의)\n",
    " * 머신러닝/딥러닝 모델링 후 성능 비교\n",
    " * 최적AI 모델 선정 및 저장\n",
    " * 새로운 출동 이력에 제시된 환자의 증상을 바탕으로 중증 질환 예측 함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f22b044",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "plt.rcParams['font.family'] = 'Malgun Gothic'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "11e97a5c-ea39-41af-9519-62247a9c2f3e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 응급 출동 데이터 불러오기\n",
    "# 파일명 : 119_emergency_dispatch.csv, encoding='cp949'\n",
    "# 중증 질환이 ['심근경색', '복부손상', '뇌경색', '뇌출혈']인 데이터만 추출\n",
    "# 데이터 랜덤으로 섞기\n",
    "\n",
    "data = pd.read_csv( '119_emergency_dispatch.csv', encoding='cp949' )\n",
    "desease = data[data['중증질환'].isin(['심근경색', '복부손상', '뇌경색', '뇌출혈'])]\n",
    "\n",
    "# 데이터 랜덤으로 섞기\n",
    "\n",
    "desease = desease.sample(frac=1).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72128961-d182-45c6-b50a-cd023e5b784f",
   "metadata": {},
   "source": [
    "### 1) 학습용, 평가용 데이터 준비하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "156e1144-5b0f-468b-a240-e12db8727f53",
   "metadata": {},
   "source": [
    "* 데이터 전처리 함수 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "0a9c57ad-7d6b-4d45-82ce-e062ff9e8184",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#########################################\n",
    "# 1. 함수 선언하기                       #\n",
    "#########################################\n",
    "# 함수명 : preprocessing\n",
    "# 매개변수 : desease (응급 출동 데이터 중 중증 질환이 ['심근경색', '복부손상', '뇌경색', '뇌출혈']인 데이터프레임)\n",
    "\n",
    "def preprocessing(desease):\n",
    "\n",
    "    desease = desease.copy()\n",
    "    #########################################\n",
    "    # 2. 데이터 전처리 하기                  #\n",
    "    #########################################\n",
    "    \n",
    "    # '발열' 컬럼 구하기 : 체온이 37도 이상이면 1, 아니면 0\n",
    "    desease['발열'] = [1 if x>=37  else 0 for x in desease['체온']]\n",
    "\n",
    "    # '고혈압' 칼럼 구하기 : 수축기 혈압이 140 이상이면 1, 아니면 0\n",
    "    desease['고혈압'] = [ 1 if x>=140  else 0 for x in desease['수축기 혈압']]\n",
    "\n",
    "    # '저혈압' 칼럼 구하기 : 수축기 혈압이 90 이하이면 1, 아니면 0\n",
    "    desease['저혈압'] = [ 1 if x<= 90  else 0 for x in desease['수축기 혈압']]\n",
    "    \n",
    "    #########################################\n",
    "    # 3. X에 선택된 Feature값 넣기           #\n",
    "    #########################################\n",
    "    # X : '중증질환' 및 데이터분석에서 Target에 영향을 주지 않는 칼럼 제외한 나머지\n",
    "    # X = desease.drop(columns =['출동일시','중증질환', 'ID','이름', '성별', '나이','이송 시간'] )\n",
    "    X = desease.drop(columns =['출동일시','ID','이름', '성별', '나이'] )\n",
    "\n",
    "    #########################################\n",
    "    # 4. X 반환하기                       #\n",
    "    #########################################\n",
    "\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7d8963fe-aa01-4c66-a663-48c0895036c9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# target 중증질환 값을 Y에 저장\n",
    "# desease 데이터 프레임을 preprocessing 함수를 활용하여 데이터 전처리하여 필요한 feature만 X에 저장\n",
    "\n",
    "Y = desease['중증질환']\n",
    "X = preprocessing(desease)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4c690f54-b206-43d8-ab19-7228d0150a09",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# AI 모델링을 위한 학습/검증 데이터 나누기 : train_test_split\n",
    "# 데이터 분할 비율: 학습데이터 7 : 검증데이터 3\n",
    "# random_state = 2023\n",
    "# 변수명 : train_x, test_x, train_y, test_y\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_x, test_x, train_y, test_y = train_test_split(X, Y, test_size = 0.3, random_state=2023)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6703af05-a75f-407b-9aa1-87f73d49dbd1",
   "metadata": {},
   "source": [
    "### 2) 모델링"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0a3a6a9-9a9b-47b5-8457-a918c33ce880",
   "metadata": {},
   "source": [
    " * 활용 모델 : DecisionTreeClassifier, RandomForestClassifier, XGBClassifier, DNN\n",
    " * 성능 평가 : accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "479c8b5b-eaff-4ffe-9064-ab6916442edc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9142521534847299\n"
     ]
    }
   ],
   "source": [
    "## Decision Tree\n",
    "## 1) 불러오기\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "## 2) 선언하기\n",
    "\n",
    "model_DTC = DecisionTreeClassifier(max_depth = 15, random_state = 2023)\n",
    "\n",
    "## 3) 학습하기\n",
    "model_DTC.fit(train_x, train_y)\n",
    "\n",
    "\n",
    "## 4) 예측하기\n",
    "pred_DTC = model_DTC.predict(test_x) \n",
    "\n",
    "## 5) 평가하기\n",
    "print(accuracy_score(test_y, pred_DTC) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7d1975bb-868d-4edb-b002-c77516a36bc5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9265857478465153\n"
     ]
    }
   ],
   "source": [
    "## RandomForest\n",
    "## 1) 불러오기\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "## 2) 선언하기\n",
    "\n",
    "model_RFC = RandomForestClassifier(max_depth = 15, random_state = 2023)\n",
    "\n",
    "## 3) 학습하기\n",
    "model_RFC.fit(train_x, train_y)\n",
    "\n",
    "\n",
    "## 4) 예측하기\n",
    "pred_RFC = model_RFC.predict(test_x)\n",
    "\n",
    "## 5) 평가하기\n",
    "print(accuracy_score(test_y, pred_RFC) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ce030325-6ca6-4a7f-bb56-e01372cf6ca9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9234534064212999\n"
     ]
    }
   ],
   "source": [
    "## XGBoost\n",
    "## 1) 불러오기\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "## 2) 선언하기\n",
    "\n",
    "model_XGC = XGBClassifier(max_depth = 3, random_state = 2023)\n",
    "\n",
    "\n",
    "## target값 라벨링하기 {'뇌경색':0, '뇌출혈':1, '복부손상':2, '심근경색':3}\n",
    "\n",
    "labeling = {'뇌경색':0, '뇌출혈':1, '복부손상':2, '심근경색':3}\n",
    "\n",
    "train_y_1 = train_y.replace(labeling)\n",
    "test_y_1 = test_y.replace(labeling)\n",
    "\n",
    "## 3) 학습하기\n",
    "\n",
    "model_XGC.fit(train_x, train_y_1)\n",
    "\n",
    "## 4) 예측하기\n",
    "pred_XGC = model_XGC.predict(test_x)\n",
    "\n",
    "## 5) 평가하기\n",
    "print(accuracy_score(test_y_1, pred_XGC) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd3556d-f86a-454a-ac18-3e784aba0614",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "d5d9f020-f736-462a-9060-bb980e4a4190",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "298/298 [==============================] - 1s 2ms/step - loss: 1.2474 - accuracy: 0.4772 - val_loss: 0.9340 - val_accuracy: 0.6816\n",
      "Epoch 2/300\n",
      "298/298 [==============================] - 0s 1ms/step - loss: 0.6718 - accuracy: 0.7826 - val_loss: 0.4935 - val_accuracy: 0.8180\n",
      "Epoch 3/300\n",
      "298/298 [==============================] - 0s 1ms/step - loss: 0.4234 - accuracy: 0.8635 - val_loss: 0.3709 - val_accuracy: 0.8826\n",
      "Epoch 4/300\n",
      "298/298 [==============================] - 0s 1ms/step - loss: 0.3402 - accuracy: 0.8920 - val_loss: 0.3268 - val_accuracy: 0.8897\n",
      "Epoch 5/300\n",
      "298/298 [==============================] - 1s 2ms/step - loss: 0.3089 - accuracy: 0.9016 - val_loss: 0.3042 - val_accuracy: 0.9031\n",
      "Epoch 6/300\n",
      "298/298 [==============================] - 1s 2ms/step - loss: 0.2908 - accuracy: 0.9050 - val_loss: 0.2907 - val_accuracy: 0.9048\n",
      "Epoch 7/300\n",
      "298/298 [==============================] - 1s 2ms/step - loss: 0.2791 - accuracy: 0.9076 - val_loss: 0.2805 - val_accuracy: 0.9090\n",
      "Epoch 8/300\n",
      "298/298 [==============================] - 1s 2ms/step - loss: 0.2714 - accuracy: 0.9095 - val_loss: 0.2758 - val_accuracy: 0.9094\n",
      "Epoch 9/300\n",
      "298/298 [==============================] - 1s 2ms/step - loss: 0.2654 - accuracy: 0.9104 - val_loss: 0.2704 - val_accuracy: 0.9119\n",
      "Epoch 10/300\n",
      "298/298 [==============================] - 1s 2ms/step - loss: 0.2613 - accuracy: 0.9098 - val_loss: 0.2657 - val_accuracy: 0.9111\n",
      "Epoch 11/300\n",
      "298/298 [==============================] - 1s 2ms/step - loss: 0.2575 - accuracy: 0.9112 - val_loss: 0.2651 - val_accuracy: 0.9094\n",
      "Epoch 12/300\n",
      "298/298 [==============================] - 1s 2ms/step - loss: 0.2541 - accuracy: 0.9109 - val_loss: 0.2612 - val_accuracy: 0.9119\n",
      "Epoch 13/300\n",
      "298/298 [==============================] - 1s 2ms/step - loss: 0.2514 - accuracy: 0.9116 - val_loss: 0.2577 - val_accuracy: 0.9115\n",
      "Epoch 14/300\n",
      "298/298 [==============================] - 1s 2ms/step - loss: 0.2484 - accuracy: 0.9117 - val_loss: 0.2565 - val_accuracy: 0.9123\n",
      "Epoch 15/300\n",
      "298/298 [==============================] - 1s 2ms/step - loss: 0.2459 - accuracy: 0.9116 - val_loss: 0.2550 - val_accuracy: 0.9132\n",
      "Epoch 16/300\n",
      "298/298 [==============================] - 1s 2ms/step - loss: 0.2438 - accuracy: 0.9126 - val_loss: 0.2534 - val_accuracy: 0.9144\n",
      "Epoch 17/300\n",
      "298/298 [==============================] - 1s 3ms/step - loss: 0.2418 - accuracy: 0.9126 - val_loss: 0.2497 - val_accuracy: 0.9115\n",
      "Epoch 18/300\n",
      "298/298 [==============================] - 1s 3ms/step - loss: 0.2397 - accuracy: 0.9135 - val_loss: 0.2494 - val_accuracy: 0.9153\n",
      "Epoch 19/300\n",
      "298/298 [==============================] - 1s 3ms/step - loss: 0.2385 - accuracy: 0.9156 - val_loss: 0.2478 - val_accuracy: 0.9144\n",
      "Epoch 20/300\n",
      "298/298 [==============================] - 1s 2ms/step - loss: 0.2372 - accuracy: 0.9139 - val_loss: 0.2457 - val_accuracy: 0.9161\n",
      "Epoch 21/300\n",
      "298/298 [==============================] - 1s 2ms/step - loss: 0.2357 - accuracy: 0.9165 - val_loss: 0.2450 - val_accuracy: 0.9169\n",
      "Epoch 22/300\n",
      "298/298 [==============================] - 1s 2ms/step - loss: 0.2337 - accuracy: 0.9166 - val_loss: 0.2430 - val_accuracy: 0.9169\n",
      "Epoch 23/300\n",
      "298/298 [==============================] - 1s 3ms/step - loss: 0.2324 - accuracy: 0.9152 - val_loss: 0.2408 - val_accuracy: 0.9161\n",
      "Epoch 24/300\n",
      "298/298 [==============================] - 1s 2ms/step - loss: 0.2313 - accuracy: 0.9151 - val_loss: 0.2389 - val_accuracy: 0.9169\n",
      "Epoch 25/300\n",
      "298/298 [==============================] - 1s 3ms/step - loss: 0.2302 - accuracy: 0.9177 - val_loss: 0.2371 - val_accuracy: 0.9174\n",
      "Epoch 26/300\n",
      "298/298 [==============================] - 1s 3ms/step - loss: 0.2286 - accuracy: 0.9173 - val_loss: 0.2377 - val_accuracy: 0.9190\n",
      "Epoch 27/300\n",
      "298/298 [==============================] - 1s 3ms/step - loss: 0.2276 - accuracy: 0.9189 - val_loss: 0.2359 - val_accuracy: 0.9178\n",
      "Epoch 28/300\n",
      "298/298 [==============================] - 1s 2ms/step - loss: 0.2269 - accuracy: 0.9172 - val_loss: 0.2351 - val_accuracy: 0.9186\n",
      "Epoch 29/300\n",
      "298/298 [==============================] - 1s 3ms/step - loss: 0.2248 - accuracy: 0.9182 - val_loss: 0.2311 - val_accuracy: 0.9195\n",
      "Epoch 30/300\n",
      "298/298 [==============================] - 1s 3ms/step - loss: 0.2244 - accuracy: 0.9185 - val_loss: 0.2310 - val_accuracy: 0.9174\n",
      "Epoch 31/300\n",
      "298/298 [==============================] - 1s 3ms/step - loss: 0.2227 - accuracy: 0.9178 - val_loss: 0.2300 - val_accuracy: 0.9174\n",
      "Epoch 32/300\n",
      "298/298 [==============================] - 1s 2ms/step - loss: 0.2220 - accuracy: 0.9180 - val_loss: 0.2290 - val_accuracy: 0.9203\n",
      "Epoch 33/300\n",
      "298/298 [==============================] - 1s 2ms/step - loss: 0.2209 - accuracy: 0.9182 - val_loss: 0.2293 - val_accuracy: 0.9195\n",
      "Epoch 34/300\n",
      "298/298 [==============================] - 1s 2ms/step - loss: 0.2209 - accuracy: 0.9182 - val_loss: 0.2262 - val_accuracy: 0.9199\n",
      "Epoch 35/300\n",
      "298/298 [==============================] - 1s 2ms/step - loss: 0.2197 - accuracy: 0.9194 - val_loss: 0.2283 - val_accuracy: 0.9207\n",
      "Epoch 36/300\n",
      "298/298 [==============================] - 1s 2ms/step - loss: 0.2197 - accuracy: 0.9198 - val_loss: 0.2280 - val_accuracy: 0.9224\n",
      "Epoch 37/300\n",
      "298/298 [==============================] - 1s 2ms/step - loss: 0.2189 - accuracy: 0.9192 - val_loss: 0.2266 - val_accuracy: 0.9232\n",
      "Epoch 38/300\n",
      "298/298 [==============================] - 1s 3ms/step - loss: 0.2177 - accuracy: 0.9199 - val_loss: 0.2255 - val_accuracy: 0.9207\n",
      "Epoch 39/300\n",
      "298/298 [==============================] - 1s 3ms/step - loss: 0.2174 - accuracy: 0.9208 - val_loss: 0.2233 - val_accuracy: 0.9199\n",
      "Epoch 40/300\n",
      "298/298 [==============================] - 1s 3ms/step - loss: 0.2170 - accuracy: 0.9209 - val_loss: 0.2272 - val_accuracy: 0.9220\n",
      "Epoch 41/300\n",
      "298/298 [==============================] - 1s 3ms/step - loss: 0.2168 - accuracy: 0.9203 - val_loss: 0.2235 - val_accuracy: 0.9216\n",
      "Epoch 42/300\n",
      "298/298 [==============================] - 1s 2ms/step - loss: 0.2163 - accuracy: 0.9204 - val_loss: 0.2229 - val_accuracy: 0.9216\n",
      "Epoch 43/300\n",
      "298/298 [==============================] - 1s 2ms/step - loss: 0.2152 - accuracy: 0.9215 - val_loss: 0.2239 - val_accuracy: 0.9207\n",
      "Epoch 44/300\n",
      "298/298 [==============================] - 1s 3ms/step - loss: 0.2155 - accuracy: 0.9206 - val_loss: 0.2238 - val_accuracy: 0.9203\n",
      "Epoch 45/300\n",
      "298/298 [==============================] - 1s 2ms/step - loss: 0.2147 - accuracy: 0.9212 - val_loss: 0.2219 - val_accuracy: 0.9207\n",
      "Epoch 46/300\n",
      "298/298 [==============================] - 1s 2ms/step - loss: 0.2146 - accuracy: 0.9205 - val_loss: 0.2237 - val_accuracy: 0.9232\n",
      "Epoch 47/300\n",
      "298/298 [==============================] - 1s 2ms/step - loss: 0.2142 - accuracy: 0.9213 - val_loss: 0.2224 - val_accuracy: 0.9220\n",
      "Epoch 48/300\n",
      "298/298 [==============================] - 1s 2ms/step - loss: 0.2142 - accuracy: 0.9207 - val_loss: 0.2218 - val_accuracy: 0.9203\n",
      "Epoch 49/300\n",
      "298/298 [==============================] - 0s 2ms/step - loss: 0.2132 - accuracy: 0.9215 - val_loss: 0.2262 - val_accuracy: 0.9220\n",
      "Epoch 50/300\n",
      "298/298 [==============================] - 1s 2ms/step - loss: 0.2135 - accuracy: 0.9213 - val_loss: 0.2209 - val_accuracy: 0.9224\n",
      "Epoch 51/300\n",
      "298/298 [==============================] - 1s 2ms/step - loss: 0.2124 - accuracy: 0.9217 - val_loss: 0.2208 - val_accuracy: 0.9211\n",
      "Epoch 52/300\n",
      "298/298 [==============================] - 1s 2ms/step - loss: 0.2124 - accuracy: 0.9216 - val_loss: 0.2219 - val_accuracy: 0.9228\n",
      "Epoch 53/300\n",
      "298/298 [==============================] - 1s 2ms/step - loss: 0.2117 - accuracy: 0.9214 - val_loss: 0.2220 - val_accuracy: 0.9228\n",
      "Epoch 54/300\n",
      "298/298 [==============================] - 1s 2ms/step - loss: 0.2125 - accuracy: 0.9209 - val_loss: 0.2214 - val_accuracy: 0.9216\n",
      "Epoch 55/300\n",
      "298/298 [==============================] - 1s 2ms/step - loss: 0.2116 - accuracy: 0.9206 - val_loss: 0.2214 - val_accuracy: 0.9224\n",
      "Epoch 56/300\n",
      "298/298 [==============================] - 1s 2ms/step - loss: 0.2115 - accuracy: 0.9219 - val_loss: 0.2208 - val_accuracy: 0.9237\n",
      "Epoch 57/300\n",
      "298/298 [==============================] - 1s 2ms/step - loss: 0.2114 - accuracy: 0.9206 - val_loss: 0.2222 - val_accuracy: 0.9232\n",
      "Epoch 58/300\n",
      "298/298 [==============================] - 1s 2ms/step - loss: 0.2112 - accuracy: 0.9217 - val_loss: 0.2204 - val_accuracy: 0.9211\n",
      "Epoch 59/300\n",
      "298/298 [==============================] - 1s 2ms/step - loss: 0.2108 - accuracy: 0.9214 - val_loss: 0.2183 - val_accuracy: 0.9220\n",
      "Epoch 60/300\n",
      "298/298 [==============================] - 1s 2ms/step - loss: 0.2098 - accuracy: 0.9214 - val_loss: 0.2221 - val_accuracy: 0.9237\n",
      "Epoch 61/300\n",
      "298/298 [==============================] - 1s 2ms/step - loss: 0.2100 - accuracy: 0.9210 - val_loss: 0.2209 - val_accuracy: 0.9220\n",
      "Epoch 62/300\n",
      "298/298 [==============================] - 1s 2ms/step - loss: 0.2094 - accuracy: 0.9220 - val_loss: 0.2181 - val_accuracy: 0.9211\n",
      "Epoch 63/300\n",
      "298/298 [==============================] - 1s 3ms/step - loss: 0.2097 - accuracy: 0.9236 - val_loss: 0.2176 - val_accuracy: 0.9211\n",
      "Epoch 64/300\n",
      "298/298 [==============================] - 1s 3ms/step - loss: 0.2099 - accuracy: 0.9230 - val_loss: 0.2179 - val_accuracy: 0.9228\n",
      "Epoch 65/300\n",
      "298/298 [==============================] - 1s 2ms/step - loss: 0.2092 - accuracy: 0.9205 - val_loss: 0.2171 - val_accuracy: 0.9232\n",
      "Epoch 66/300\n",
      "298/298 [==============================] - 1s 2ms/step - loss: 0.2089 - accuracy: 0.9221 - val_loss: 0.2159 - val_accuracy: 0.9211\n",
      "Epoch 67/300\n",
      "298/298 [==============================] - 1s 2ms/step - loss: 0.2081 - accuracy: 0.9212 - val_loss: 0.2178 - val_accuracy: 0.9228\n",
      "Epoch 68/300\n",
      "298/298 [==============================] - 1s 2ms/step - loss: 0.2086 - accuracy: 0.9210 - val_loss: 0.2201 - val_accuracy: 0.9237\n",
      "Epoch 69/300\n",
      "298/298 [==============================] - 1s 2ms/step - loss: 0.2087 - accuracy: 0.9204 - val_loss: 0.2162 - val_accuracy: 0.9241\n",
      "Epoch 70/300\n",
      "298/298 [==============================] - 1s 3ms/step - loss: 0.2079 - accuracy: 0.9208 - val_loss: 0.2194 - val_accuracy: 0.9216\n",
      "Epoch 71/300\n",
      "298/298 [==============================] - 1s 2ms/step - loss: 0.2083 - accuracy: 0.9217 - val_loss: 0.2167 - val_accuracy: 0.9224\n",
      "Epoch 72/300\n",
      "298/298 [==============================] - 1s 3ms/step - loss: 0.2076 - accuracy: 0.9228 - val_loss: 0.2196 - val_accuracy: 0.9224\n",
      "Epoch 73/300\n",
      "298/298 [==============================] - 1s 2ms/step - loss: 0.2077 - accuracy: 0.9235 - val_loss: 0.2175 - val_accuracy: 0.9228\n",
      "Epoch 74/300\n",
      "298/298 [==============================] - 1s 2ms/step - loss: 0.2081 - accuracy: 0.9209 - val_loss: 0.2149 - val_accuracy: 0.9241\n",
      "Epoch 75/300\n",
      "298/298 [==============================] - 1s 2ms/step - loss: 0.2069 - accuracy: 0.9215 - val_loss: 0.2129 - val_accuracy: 0.9220\n",
      "Epoch 76/300\n",
      "298/298 [==============================] - 1s 2ms/step - loss: 0.2068 - accuracy: 0.9229 - val_loss: 0.2153 - val_accuracy: 0.9237\n",
      "Epoch 77/300\n",
      "298/298 [==============================] - 1s 2ms/step - loss: 0.2066 - accuracy: 0.9223 - val_loss: 0.2138 - val_accuracy: 0.9245\n",
      "Epoch 78/300\n",
      "298/298 [==============================] - 1s 2ms/step - loss: 0.2065 - accuracy: 0.9222 - val_loss: 0.2154 - val_accuracy: 0.9232\n",
      "Epoch 79/300\n",
      "298/298 [==============================] - 1s 2ms/step - loss: 0.2072 - accuracy: 0.9222 - val_loss: 0.2146 - val_accuracy: 0.9237\n",
      "Epoch 80/300\n",
      "298/298 [==============================] - 1s 2ms/step - loss: 0.2059 - accuracy: 0.9217 - val_loss: 0.2146 - val_accuracy: 0.9228\n",
      "Epoch 81/300\n",
      "298/298 [==============================] - 1s 3ms/step - loss: 0.2062 - accuracy: 0.9224 - val_loss: 0.2136 - val_accuracy: 0.9228\n",
      "Epoch 82/300\n",
      "298/298 [==============================] - 1s 2ms/step - loss: 0.2063 - accuracy: 0.9219 - val_loss: 0.2137 - val_accuracy: 0.9232\n",
      "Epoch 83/300\n",
      "298/298 [==============================] - 0s 2ms/step - loss: 0.2053 - accuracy: 0.9226 - val_loss: 0.2149 - val_accuracy: 0.9237\n",
      "Epoch 84/300\n",
      "298/298 [==============================] - 1s 2ms/step - loss: 0.2061 - accuracy: 0.9224 - val_loss: 0.2135 - val_accuracy: 0.9249\n",
      "Epoch 85/300\n",
      "298/298 [==============================] - 1s 2ms/step - loss: 0.2060 - accuracy: 0.9225 - val_loss: 0.2134 - val_accuracy: 0.9228\n",
      "Epoch 86/300\n",
      "298/298 [==============================] - 1s 3ms/step - loss: 0.2054 - accuracy: 0.9207 - val_loss: 0.2138 - val_accuracy: 0.9228\n",
      "Epoch 87/300\n",
      "298/298 [==============================] - 1s 4ms/step - loss: 0.2048 - accuracy: 0.9224 - val_loss: 0.2174 - val_accuracy: 0.9258\n",
      "Epoch 88/300\n",
      "298/298 [==============================] - 1s 3ms/step - loss: 0.2051 - accuracy: 0.9217 - val_loss: 0.2129 - val_accuracy: 0.9245\n",
      "Epoch 89/300\n",
      "298/298 [==============================] - 1s 3ms/step - loss: 0.2051 - accuracy: 0.9215 - val_loss: 0.2120 - val_accuracy: 0.9237\n",
      "Epoch 90/300\n",
      "298/298 [==============================] - 1s 4ms/step - loss: 0.2052 - accuracy: 0.9220 - val_loss: 0.2127 - val_accuracy: 0.9232\n",
      "Epoch 91/300\n",
      "298/298 [==============================] - 1s 3ms/step - loss: 0.2050 - accuracy: 0.9226 - val_loss: 0.2114 - val_accuracy: 0.9237\n",
      "Epoch 92/300\n",
      "298/298 [==============================] - 1s 3ms/step - loss: 0.2043 - accuracy: 0.9221 - val_loss: 0.2140 - val_accuracy: 0.9245\n",
      "Epoch 93/300\n",
      "298/298 [==============================] - 1s 3ms/step - loss: 0.2050 - accuracy: 0.9215 - val_loss: 0.2146 - val_accuracy: 0.9228\n",
      "Epoch 94/300\n",
      "298/298 [==============================] - 1s 3ms/step - loss: 0.2037 - accuracy: 0.9237 - val_loss: 0.2135 - val_accuracy: 0.9245\n",
      "Epoch 95/300\n",
      "298/298 [==============================] - 1s 2ms/step - loss: 0.2037 - accuracy: 0.9221 - val_loss: 0.2150 - val_accuracy: 0.9249\n",
      "Epoch 96/300\n",
      "298/298 [==============================] - 1s 2ms/step - loss: 0.2036 - accuracy: 0.9229 - val_loss: 0.2120 - val_accuracy: 0.9237\n",
      "Epoch 97/300\n",
      "298/298 [==============================] - 1s 3ms/step - loss: 0.2039 - accuracy: 0.9228 - val_loss: 0.2103 - val_accuracy: 0.9249\n",
      "Epoch 98/300\n",
      "298/298 [==============================] - 1s 2ms/step - loss: 0.2041 - accuracy: 0.9221 - val_loss: 0.2111 - val_accuracy: 0.9237\n",
      "Epoch 99/300\n",
      "298/298 [==============================] - 1s 2ms/step - loss: 0.2040 - accuracy: 0.9227 - val_loss: 0.2136 - val_accuracy: 0.9249\n",
      "Epoch 100/300\n",
      "298/298 [==============================] - 1s 2ms/step - loss: 0.2037 - accuracy: 0.9224 - val_loss: 0.2124 - val_accuracy: 0.9258\n",
      "Epoch 101/300\n",
      "298/298 [==============================] - 1s 3ms/step - loss: 0.2036 - accuracy: 0.9223 - val_loss: 0.2122 - val_accuracy: 0.9241\n",
      "Epoch 102/300\n",
      "298/298 [==============================] - 1s 2ms/step - loss: 0.2034 - accuracy: 0.9228 - val_loss: 0.2106 - val_accuracy: 0.9274\n",
      "Epoch 103/300\n",
      "298/298 [==============================] - 1s 3ms/step - loss: 0.2032 - accuracy: 0.9224 - val_loss: 0.2125 - val_accuracy: 0.9241\n",
      "Epoch 104/300\n",
      "298/298 [==============================] - 1s 2ms/step - loss: 0.2029 - accuracy: 0.9228 - val_loss: 0.2144 - val_accuracy: 0.9249\n",
      "Epoch 105/300\n",
      "298/298 [==============================] - 1s 3ms/step - loss: 0.2034 - accuracy: 0.9221 - val_loss: 0.2118 - val_accuracy: 0.9253\n",
      "Epoch 106/300\n",
      "298/298 [==============================] - 1s 3ms/step - loss: 0.2028 - accuracy: 0.9236 - val_loss: 0.2144 - val_accuracy: 0.9253\n",
      "Epoch 107/300\n",
      "298/298 [==============================] - 1s 3ms/step - loss: 0.2038 - accuracy: 0.9217 - val_loss: 0.2096 - val_accuracy: 0.9249\n",
      "Epoch 108/300\n",
      "298/298 [==============================] - 1s 3ms/step - loss: 0.2023 - accuracy: 0.9227 - val_loss: 0.2097 - val_accuracy: 0.9237\n",
      "Epoch 109/300\n",
      "298/298 [==============================] - 1s 2ms/step - loss: 0.2031 - accuracy: 0.9227 - val_loss: 0.2111 - val_accuracy: 0.9270\n",
      "Epoch 110/300\n",
      "298/298 [==============================] - 1s 2ms/step - loss: 0.2028 - accuracy: 0.9232 - val_loss: 0.2102 - val_accuracy: 0.9262\n",
      "Epoch 111/300\n",
      "298/298 [==============================] - 1s 2ms/step - loss: 0.2017 - accuracy: 0.9233 - val_loss: 0.2110 - val_accuracy: 0.9262\n",
      "Epoch 112/300\n",
      "298/298 [==============================] - 1s 2ms/step - loss: 0.2021 - accuracy: 0.9228 - val_loss: 0.2130 - val_accuracy: 0.9253\n",
      "Epoch 113/300\n",
      "298/298 [==============================] - 1s 3ms/step - loss: 0.2025 - accuracy: 0.9220 - val_loss: 0.2123 - val_accuracy: 0.9258\n",
      "Epoch 114/300\n",
      "298/298 [==============================] - 1s 2ms/step - loss: 0.2028 - accuracy: 0.9233 - val_loss: 0.2083 - val_accuracy: 0.9249\n",
      "Epoch 115/300\n",
      "298/298 [==============================] - 1s 2ms/step - loss: 0.2021 - accuracy: 0.9227 - val_loss: 0.2083 - val_accuracy: 0.9249\n",
      "Epoch 116/300\n",
      "298/298 [==============================] - 1s 3ms/step - loss: 0.2019 - accuracy: 0.9226 - val_loss: 0.2095 - val_accuracy: 0.9253\n",
      "Epoch 117/300\n",
      "298/298 [==============================] - 1s 2ms/step - loss: 0.2018 - accuracy: 0.9226 - val_loss: 0.2106 - val_accuracy: 0.9241\n",
      "Epoch 118/300\n",
      "298/298 [==============================] - 1s 3ms/step - loss: 0.2016 - accuracy: 0.9230 - val_loss: 0.2105 - val_accuracy: 0.9245\n",
      "Epoch 119/300\n",
      "298/298 [==============================] - 1s 2ms/step - loss: 0.2020 - accuracy: 0.9221 - val_loss: 0.2084 - val_accuracy: 0.9249\n",
      "Epoch 120/300\n",
      "298/298 [==============================] - 1s 2ms/step - loss: 0.2019 - accuracy: 0.9227 - val_loss: 0.2078 - val_accuracy: 0.9245\n",
      "Epoch 121/300\n",
      "298/298 [==============================] - 1s 2ms/step - loss: 0.2017 - accuracy: 0.9221 - val_loss: 0.2097 - val_accuracy: 0.9262\n",
      "Epoch 122/300\n",
      "298/298 [==============================] - 1s 2ms/step - loss: 0.2017 - accuracy: 0.9241 - val_loss: 0.2073 - val_accuracy: 0.9245\n",
      "Epoch 123/300\n",
      "298/298 [==============================] - 1s 2ms/step - loss: 0.2019 - accuracy: 0.9241 - val_loss: 0.2069 - val_accuracy: 0.9279\n",
      "Epoch 124/300\n",
      "298/298 [==============================] - 1s 3ms/step - loss: 0.2011 - accuracy: 0.9239 - val_loss: 0.2152 - val_accuracy: 0.9195\n",
      "Epoch 125/300\n",
      "298/298 [==============================] - 1s 2ms/step - loss: 0.2011 - accuracy: 0.9217 - val_loss: 0.2092 - val_accuracy: 0.9262\n",
      "Epoch 126/300\n",
      "298/298 [==============================] - 1s 3ms/step - loss: 0.2012 - accuracy: 0.9226 - val_loss: 0.2070 - val_accuracy: 0.9253\n",
      "Epoch 127/300\n",
      "298/298 [==============================] - 1s 3ms/step - loss: 0.2009 - accuracy: 0.9230 - val_loss: 0.2070 - val_accuracy: 0.9253\n",
      "Epoch 128/300\n",
      "298/298 [==============================] - 1s 3ms/step - loss: 0.2008 - accuracy: 0.9221 - val_loss: 0.2073 - val_accuracy: 0.9241\n",
      "Epoch 129/300\n",
      "298/298 [==============================] - 1s 2ms/step - loss: 0.2006 - accuracy: 0.9221 - val_loss: 0.2068 - val_accuracy: 0.9258\n",
      "Epoch 130/300\n",
      "298/298 [==============================] - 1s 2ms/step - loss: 0.2005 - accuracy: 0.9230 - val_loss: 0.2060 - val_accuracy: 0.9274\n",
      "Epoch 131/300\n",
      "298/298 [==============================] - 1s 2ms/step - loss: 0.2005 - accuracy: 0.9230 - val_loss: 0.2117 - val_accuracy: 0.9253\n",
      "Epoch 132/300\n",
      "298/298 [==============================] - 1s 2ms/step - loss: 0.2005 - accuracy: 0.9229 - val_loss: 0.2068 - val_accuracy: 0.9270\n",
      "Epoch 133/300\n",
      "298/298 [==============================] - 1s 3ms/step - loss: 0.1999 - accuracy: 0.9238 - val_loss: 0.2057 - val_accuracy: 0.9270\n",
      "Epoch 134/300\n",
      "298/298 [==============================] - 1s 2ms/step - loss: 0.1990 - accuracy: 0.9225 - val_loss: 0.2083 - val_accuracy: 0.9274\n",
      "Epoch 135/300\n",
      "298/298 [==============================] - 1s 2ms/step - loss: 0.2004 - accuracy: 0.9232 - val_loss: 0.2053 - val_accuracy: 0.9266\n",
      "Epoch 136/300\n",
      "298/298 [==============================] - 1s 2ms/step - loss: 0.1995 - accuracy: 0.9228 - val_loss: 0.2076 - val_accuracy: 0.9262\n",
      "Epoch 137/300\n",
      "298/298 [==============================] - 1s 2ms/step - loss: 0.2006 - accuracy: 0.9226 - val_loss: 0.2032 - val_accuracy: 0.9270\n",
      "Epoch 138/300\n",
      "298/298 [==============================] - 1s 3ms/step - loss: 0.1989 - accuracy: 0.9222 - val_loss: 0.2047 - val_accuracy: 0.9266\n",
      "Epoch 139/300\n",
      "298/298 [==============================] - 1s 3ms/step - loss: 0.1992 - accuracy: 0.9219 - val_loss: 0.2062 - val_accuracy: 0.9249\n",
      "Epoch 140/300\n",
      "298/298 [==============================] - 1s 3ms/step - loss: 0.1993 - accuracy: 0.9233 - val_loss: 0.2053 - val_accuracy: 0.9249\n",
      "Epoch 141/300\n",
      "298/298 [==============================] - 1s 3ms/step - loss: 0.1988 - accuracy: 0.9231 - val_loss: 0.2068 - val_accuracy: 0.9279\n",
      "Epoch 142/300\n",
      "298/298 [==============================] - 1s 3ms/step - loss: 0.1988 - accuracy: 0.9235 - val_loss: 0.2050 - val_accuracy: 0.9262\n",
      "Epoch 143/300\n",
      "298/298 [==============================] - 1s 3ms/step - loss: 0.1985 - accuracy: 0.9241 - val_loss: 0.2031 - val_accuracy: 0.9262\n",
      "Epoch 144/300\n",
      "298/298 [==============================] - 1s 3ms/step - loss: 0.1987 - accuracy: 0.9221 - val_loss: 0.2074 - val_accuracy: 0.9279\n",
      "Epoch 145/300\n",
      "298/298 [==============================] - 1s 3ms/step - loss: 0.1983 - accuracy: 0.9235 - val_loss: 0.2039 - val_accuracy: 0.9274\n",
      "Epoch 146/300\n",
      "298/298 [==============================] - 1s 2ms/step - loss: 0.1984 - accuracy: 0.9221 - val_loss: 0.2048 - val_accuracy: 0.9253\n",
      "Epoch 147/300\n",
      "298/298 [==============================] - 1s 2ms/step - loss: 0.1987 - accuracy: 0.9219 - val_loss: 0.2029 - val_accuracy: 0.9295\n",
      "Epoch 148/300\n",
      "298/298 [==============================] - 1s 3ms/step - loss: 0.1980 - accuracy: 0.9234 - val_loss: 0.2054 - val_accuracy: 0.9266\n",
      "Epoch 149/300\n",
      "298/298 [==============================] - 1s 3ms/step - loss: 0.1977 - accuracy: 0.9236 - val_loss: 0.2083 - val_accuracy: 0.9274\n",
      "Epoch 150/300\n",
      "298/298 [==============================] - 1s 3ms/step - loss: 0.1985 - accuracy: 0.9239 - val_loss: 0.2044 - val_accuracy: 0.9283\n",
      "Epoch 151/300\n",
      "298/298 [==============================] - 1s 2ms/step - loss: 0.1984 - accuracy: 0.9231 - val_loss: 0.2034 - val_accuracy: 0.9291\n",
      "Epoch 152/300\n",
      "298/298 [==============================] - 1s 3ms/step - loss: 0.1979 - accuracy: 0.9233 - val_loss: 0.2030 - val_accuracy: 0.9287\n",
      "Epoch 153/300\n",
      "298/298 [==============================] - 1s 3ms/step - loss: 0.1975 - accuracy: 0.9232 - val_loss: 0.2070 - val_accuracy: 0.9274\n",
      "Epoch 154/300\n",
      "298/298 [==============================] - 1s 2ms/step - loss: 0.1979 - accuracy: 0.9233 - val_loss: 0.2020 - val_accuracy: 0.9253\n",
      "Epoch 155/300\n",
      "298/298 [==============================] - 1s 2ms/step - loss: 0.1977 - accuracy: 0.9237 - val_loss: 0.2062 - val_accuracy: 0.9270\n",
      "Epoch 156/300\n",
      "298/298 [==============================] - 1s 2ms/step - loss: 0.1976 - accuracy: 0.9220 - val_loss: 0.2074 - val_accuracy: 0.9258\n",
      "Epoch 157/300\n",
      "298/298 [==============================] - 1s 2ms/step - loss: 0.1971 - accuracy: 0.9233 - val_loss: 0.2026 - val_accuracy: 0.9262\n",
      "Epoch 158/300\n",
      "298/298 [==============================] - 1s 2ms/step - loss: 0.1979 - accuracy: 0.9243 - val_loss: 0.2053 - val_accuracy: 0.9283\n",
      "Epoch 159/300\n",
      "298/298 [==============================] - 1s 2ms/step - loss: 0.1972 - accuracy: 0.9228 - val_loss: 0.2026 - val_accuracy: 0.9287\n",
      "Epoch 160/300\n",
      "298/298 [==============================] - 1s 2ms/step - loss: 0.1976 - accuracy: 0.9234 - val_loss: 0.2042 - val_accuracy: 0.9287\n",
      "Epoch 161/300\n",
      "298/298 [==============================] - 1s 3ms/step - loss: 0.1976 - accuracy: 0.9232 - val_loss: 0.2032 - val_accuracy: 0.9262\n",
      "Epoch 162/300\n",
      "298/298 [==============================] - 1s 2ms/step - loss: 0.1979 - accuracy: 0.9234 - val_loss: 0.2042 - val_accuracy: 0.9274\n",
      "Epoch 163/300\n",
      "298/298 [==============================] - 1s 3ms/step - loss: 0.1979 - accuracy: 0.9227 - val_loss: 0.2035 - val_accuracy: 0.9270\n",
      "Epoch 164/300\n",
      "298/298 [==============================] - 1s 3ms/step - loss: 0.1972 - accuracy: 0.9234 - val_loss: 0.2052 - val_accuracy: 0.9279\n",
      "Epoch 165/300\n",
      "298/298 [==============================] - 1s 3ms/step - loss: 0.1980 - accuracy: 0.9234 - val_loss: 0.2027 - val_accuracy: 0.9266\n",
      "Epoch 166/300\n",
      "298/298 [==============================] - 1s 3ms/step - loss: 0.1973 - accuracy: 0.9237 - val_loss: 0.2056 - val_accuracy: 0.9270\n",
      "Epoch 167/300\n",
      "298/298 [==============================] - 1s 3ms/step - loss: 0.1966 - accuracy: 0.9228 - val_loss: 0.2081 - val_accuracy: 0.9211\n",
      "Epoch 168/300\n",
      "298/298 [==============================] - 1s 2ms/step - loss: 0.1982 - accuracy: 0.9224 - val_loss: 0.2017 - val_accuracy: 0.9283\n",
      "Epoch 169/300\n",
      "298/298 [==============================] - 1s 3ms/step - loss: 0.1966 - accuracy: 0.9241 - val_loss: 0.2032 - val_accuracy: 0.9283\n",
      "Epoch 170/300\n",
      "298/298 [==============================] - 1s 3ms/step - loss: 0.1966 - accuracy: 0.9226 - val_loss: 0.2027 - val_accuracy: 0.9287\n",
      "Epoch 171/300\n",
      "298/298 [==============================] - 1s 2ms/step - loss: 0.1969 - accuracy: 0.9230 - val_loss: 0.2031 - val_accuracy: 0.9270\n",
      "Epoch 172/300\n",
      "298/298 [==============================] - 1s 3ms/step - loss: 0.1968 - accuracy: 0.9234 - val_loss: 0.2023 - val_accuracy: 0.9283\n",
      "Epoch 173/300\n",
      "298/298 [==============================] - 1s 3ms/step - loss: 0.1974 - accuracy: 0.9235 - val_loss: 0.2019 - val_accuracy: 0.9279\n",
      "Epoch 174/300\n",
      "298/298 [==============================] - 1s 3ms/step - loss: 0.1964 - accuracy: 0.9241 - val_loss: 0.2055 - val_accuracy: 0.9283\n",
      "Epoch 175/300\n",
      "298/298 [==============================] - 1s 3ms/step - loss: 0.1969 - accuracy: 0.9245 - val_loss: 0.2035 - val_accuracy: 0.9253\n",
      "Epoch 176/300\n",
      "298/298 [==============================] - 1s 2ms/step - loss: 0.1969 - accuracy: 0.9230 - val_loss: 0.2024 - val_accuracy: 0.9291\n",
      "Epoch 177/300\n",
      "298/298 [==============================] - 1s 2ms/step - loss: 0.1969 - accuracy: 0.9229 - val_loss: 0.2048 - val_accuracy: 0.9258\n",
      "Epoch 178/300\n",
      "298/298 [==============================] - 1s 2ms/step - loss: 0.1970 - accuracy: 0.9237 - val_loss: 0.2024 - val_accuracy: 0.9279\n",
      "Epoch 179/300\n",
      "298/298 [==============================] - 1s 2ms/step - loss: 0.1965 - accuracy: 0.9223 - val_loss: 0.2050 - val_accuracy: 0.9287\n",
      "Epoch 180/300\n",
      "298/298 [==============================] - 1s 3ms/step - loss: 0.1968 - accuracy: 0.9231 - val_loss: 0.2040 - val_accuracy: 0.9262\n",
      "Epoch 181/300\n",
      "298/298 [==============================] - 1s 3ms/step - loss: 0.1968 - accuracy: 0.9236 - val_loss: 0.2040 - val_accuracy: 0.9249\n",
      "Epoch 182/300\n",
      "298/298 [==============================] - 1s 2ms/step - loss: 0.1966 - accuracy: 0.9226 - val_loss: 0.2038 - val_accuracy: 0.9270\n",
      "Epoch 183/300\n",
      "298/298 [==============================] - 1s 2ms/step - loss: 0.1974 - accuracy: 0.9219 - val_loss: 0.2066 - val_accuracy: 0.9199\n",
      "Epoch 184/300\n",
      "298/298 [==============================] - 1s 3ms/step - loss: 0.1969 - accuracy: 0.9242 - val_loss: 0.2036 - val_accuracy: 0.9270\n",
      "Epoch 185/300\n",
      "298/298 [==============================] - 1s 3ms/step - loss: 0.1968 - accuracy: 0.9242 - val_loss: 0.2029 - val_accuracy: 0.9258\n",
      "Epoch 186/300\n",
      "298/298 [==============================] - 1s 3ms/step - loss: 0.1969 - accuracy: 0.9227 - val_loss: 0.2020 - val_accuracy: 0.9283\n",
      "Epoch 187/300\n",
      "298/298 [==============================] - 1s 3ms/step - loss: 0.1969 - accuracy: 0.9232 - val_loss: 0.2027 - val_accuracy: 0.9258\n",
      "Epoch 188/300\n",
      "298/298 [==============================] - 1s 3ms/step - loss: 0.1961 - accuracy: 0.9235 - val_loss: 0.2054 - val_accuracy: 0.9283\n",
      "Epoch 189/300\n",
      "298/298 [==============================] - 1s 3ms/step - loss: 0.1969 - accuracy: 0.9232 - val_loss: 0.2069 - val_accuracy: 0.9274\n",
      "Epoch 190/300\n",
      "298/298 [==============================] - 1s 3ms/step - loss: 0.1958 - accuracy: 0.9230 - val_loss: 0.2049 - val_accuracy: 0.9262\n",
      "Epoch 191/300\n",
      "298/298 [==============================] - 1s 3ms/step - loss: 0.1965 - accuracy: 0.9226 - val_loss: 0.2022 - val_accuracy: 0.9291\n",
      "Epoch 192/300\n",
      "298/298 [==============================] - 1s 2ms/step - loss: 0.1961 - accuracy: 0.9238 - val_loss: 0.2074 - val_accuracy: 0.9237\n",
      "Epoch 193/300\n",
      "298/298 [==============================] - 1s 2ms/step - loss: 0.1967 - accuracy: 0.9246 - val_loss: 0.2034 - val_accuracy: 0.9279\n",
      "Epoch 194/300\n",
      "298/298 [==============================] - 1s 2ms/step - loss: 0.1959 - accuracy: 0.9239 - val_loss: 0.2051 - val_accuracy: 0.9274\n",
      "Epoch 195/300\n",
      "298/298 [==============================] - 1s 2ms/step - loss: 0.1955 - accuracy: 0.9237 - val_loss: 0.2040 - val_accuracy: 0.9270\n",
      "Epoch 196/300\n",
      "298/298 [==============================] - 1s 3ms/step - loss: 0.1962 - accuracy: 0.9244 - val_loss: 0.2022 - val_accuracy: 0.9295\n",
      "Epoch 197/300\n",
      "298/298 [==============================] - 1s 2ms/step - loss: 0.1960 - accuracy: 0.9232 - val_loss: 0.2005 - val_accuracy: 0.9287\n",
      "Epoch 198/300\n",
      "298/298 [==============================] - 1s 2ms/step - loss: 0.1961 - accuracy: 0.9238 - val_loss: 0.2040 - val_accuracy: 0.9258\n",
      "Epoch 199/300\n",
      "298/298 [==============================] - 1s 2ms/step - loss: 0.1958 - accuracy: 0.9249 - val_loss: 0.2013 - val_accuracy: 0.9266\n",
      "Epoch 200/300\n",
      "298/298 [==============================] - 1s 3ms/step - loss: 0.1963 - accuracy: 0.9227 - val_loss: 0.2029 - val_accuracy: 0.9274\n",
      "Epoch 201/300\n",
      "298/298 [==============================] - 1s 3ms/step - loss: 0.1961 - accuracy: 0.9229 - val_loss: 0.2040 - val_accuracy: 0.9270\n",
      "Epoch 202/300\n",
      "298/298 [==============================] - 1s 3ms/step - loss: 0.1966 - accuracy: 0.9245 - val_loss: 0.2015 - val_accuracy: 0.9258\n",
      "Epoch 203/300\n",
      "298/298 [==============================] - 1s 3ms/step - loss: 0.1966 - accuracy: 0.9235 - val_loss: 0.2054 - val_accuracy: 0.9279\n",
      "Epoch 204/300\n",
      "298/298 [==============================] - 1s 3ms/step - loss: 0.1963 - accuracy: 0.9226 - val_loss: 0.2013 - val_accuracy: 0.9304\n",
      "Epoch 205/300\n",
      "298/298 [==============================] - 1s 2ms/step - loss: 0.1957 - accuracy: 0.9246 - val_loss: 0.2035 - val_accuracy: 0.9274\n",
      "Epoch 206/300\n",
      "298/298 [==============================] - 1s 3ms/step - loss: 0.1957 - accuracy: 0.9238 - val_loss: 0.2035 - val_accuracy: 0.9291\n",
      "Epoch 207/300\n",
      "298/298 [==============================] - 1s 2ms/step - loss: 0.1959 - accuracy: 0.9247 - val_loss: 0.2013 - val_accuracy: 0.9283\n",
      "Epoch 208/300\n",
      "298/298 [==============================] - 1s 2ms/step - loss: 0.1964 - accuracy: 0.9251 - val_loss: 0.2009 - val_accuracy: 0.9304\n",
      "Epoch 209/300\n",
      "298/298 [==============================] - 1s 3ms/step - loss: 0.1961 - accuracy: 0.9236 - val_loss: 0.2020 - val_accuracy: 0.9312\n",
      "Epoch 210/300\n",
      "298/298 [==============================] - 1s 2ms/step - loss: 0.1961 - accuracy: 0.9237 - val_loss: 0.2035 - val_accuracy: 0.9279\n",
      "Epoch 211/300\n",
      "298/298 [==============================] - 1s 2ms/step - loss: 0.1963 - accuracy: 0.9231 - val_loss: 0.2032 - val_accuracy: 0.9279\n",
      "Epoch 212/300\n",
      "298/298 [==============================] - 1s 2ms/step - loss: 0.1967 - accuracy: 0.9238 - val_loss: 0.2017 - val_accuracy: 0.9274\n",
      "Epoch 213/300\n",
      "298/298 [==============================] - 1s 2ms/step - loss: 0.1961 - accuracy: 0.9231 - val_loss: 0.2025 - val_accuracy: 0.9299\n",
      "Epoch 214/300\n",
      "298/298 [==============================] - 1s 2ms/step - loss: 0.1961 - accuracy: 0.9239 - val_loss: 0.2024 - val_accuracy: 0.9316\n",
      "Epoch 215/300\n",
      "298/298 [==============================] - 1s 3ms/step - loss: 0.1957 - accuracy: 0.9249 - val_loss: 0.2024 - val_accuracy: 0.9266\n",
      "Epoch 216/300\n",
      "298/298 [==============================] - 1s 3ms/step - loss: 0.1953 - accuracy: 0.9234 - val_loss: 0.2037 - val_accuracy: 0.9283\n",
      "Epoch 217/300\n",
      "298/298 [==============================] - 1s 3ms/step - loss: 0.1958 - accuracy: 0.9235 - val_loss: 0.2006 - val_accuracy: 0.9279\n",
      "Epoch 218/300\n",
      "298/298 [==============================] - 1s 3ms/step - loss: 0.1960 - accuracy: 0.9228 - val_loss: 0.2026 - val_accuracy: 0.9279\n",
      "Epoch 219/300\n",
      "298/298 [==============================] - 1s 2ms/step - loss: 0.1957 - accuracy: 0.9236 - val_loss: 0.2041 - val_accuracy: 0.9295\n",
      "Epoch 220/300\n",
      "298/298 [==============================] - 1s 3ms/step - loss: 0.1963 - accuracy: 0.9235 - val_loss: 0.2062 - val_accuracy: 0.9270\n",
      "Epoch 221/300\n",
      "298/298 [==============================] - 1s 3ms/step - loss: 0.1963 - accuracy: 0.9234 - val_loss: 0.2061 - val_accuracy: 0.9262\n",
      "Epoch 222/300\n",
      "298/298 [==============================] - 1s 3ms/step - loss: 0.1963 - accuracy: 0.9244 - val_loss: 0.2020 - val_accuracy: 0.9283\n",
      "Epoch 223/300\n",
      "298/298 [==============================] - 1s 3ms/step - loss: 0.1959 - accuracy: 0.9243 - val_loss: 0.2006 - val_accuracy: 0.9291\n",
      "Epoch 224/300\n",
      "298/298 [==============================] - 1s 2ms/step - loss: 0.1953 - accuracy: 0.9230 - val_loss: 0.2052 - val_accuracy: 0.9270\n",
      "Epoch 225/300\n",
      "298/298 [==============================] - 1s 3ms/step - loss: 0.1964 - accuracy: 0.9245 - val_loss: 0.2002 - val_accuracy: 0.9274\n",
      "Epoch 226/300\n",
      "298/298 [==============================] - 1s 3ms/step - loss: 0.1952 - accuracy: 0.9246 - val_loss: 0.2052 - val_accuracy: 0.9312\n",
      "Epoch 227/300\n",
      "298/298 [==============================] - 1s 2ms/step - loss: 0.1950 - accuracy: 0.9241 - val_loss: 0.2011 - val_accuracy: 0.9299\n",
      "Epoch 228/300\n",
      "298/298 [==============================] - 1s 2ms/step - loss: 0.1952 - accuracy: 0.9236 - val_loss: 0.1996 - val_accuracy: 0.9304\n",
      "Epoch 229/300\n",
      "298/298 [==============================] - 1s 2ms/step - loss: 0.1955 - accuracy: 0.9233 - val_loss: 0.2032 - val_accuracy: 0.9283\n",
      "Epoch 230/300\n",
      "298/298 [==============================] - 1s 3ms/step - loss: 0.1947 - accuracy: 0.9252 - val_loss: 0.2036 - val_accuracy: 0.9249\n",
      "Epoch 231/300\n",
      "298/298 [==============================] - 1s 2ms/step - loss: 0.1958 - accuracy: 0.9235 - val_loss: 0.2003 - val_accuracy: 0.9308\n",
      "Epoch 232/300\n",
      "298/298 [==============================] - 1s 3ms/step - loss: 0.1956 - accuracy: 0.9239 - val_loss: 0.2030 - val_accuracy: 0.9283\n",
      "Epoch 233/300\n",
      "298/298 [==============================] - 1s 3ms/step - loss: 0.1961 - accuracy: 0.9241 - val_loss: 0.2055 - val_accuracy: 0.9291\n",
      "Epoch 234/300\n",
      "298/298 [==============================] - 1s 2ms/step - loss: 0.1955 - accuracy: 0.9243 - val_loss: 0.2025 - val_accuracy: 0.9291\n",
      "Epoch 235/300\n",
      "298/298 [==============================] - 1s 2ms/step - loss: 0.1956 - accuracy: 0.9239 - val_loss: 0.2035 - val_accuracy: 0.9291\n",
      "Epoch 236/300\n",
      "298/298 [==============================] - 1s 2ms/step - loss: 0.1957 - accuracy: 0.9242 - val_loss: 0.2048 - val_accuracy: 0.9283\n",
      "Epoch 237/300\n",
      "298/298 [==============================] - 1s 2ms/step - loss: 0.1947 - accuracy: 0.9251 - val_loss: 0.2019 - val_accuracy: 0.9299\n",
      "Epoch 238/300\n",
      "298/298 [==============================] - 1s 2ms/step - loss: 0.1961 - accuracy: 0.9239 - val_loss: 0.2011 - val_accuracy: 0.9316\n",
      "Epoch 239/300\n",
      "298/298 [==============================] - 1s 2ms/step - loss: 0.1951 - accuracy: 0.9248 - val_loss: 0.2029 - val_accuracy: 0.9304\n",
      "Epoch 240/300\n",
      "298/298 [==============================] - 1s 3ms/step - loss: 0.1956 - accuracy: 0.9252 - val_loss: 0.2018 - val_accuracy: 0.9287\n",
      "Epoch 241/300\n",
      "298/298 [==============================] - 1s 2ms/step - loss: 0.1954 - accuracy: 0.9248 - val_loss: 0.2042 - val_accuracy: 0.9283\n",
      "Epoch 242/300\n",
      "298/298 [==============================] - 1s 2ms/step - loss: 0.1952 - accuracy: 0.9253 - val_loss: 0.2016 - val_accuracy: 0.9295\n",
      "Epoch 243/300\n",
      "298/298 [==============================] - 1s 2ms/step - loss: 0.1942 - accuracy: 0.9253 - val_loss: 0.2037 - val_accuracy: 0.9291\n",
      "Epoch 244/300\n",
      "298/298 [==============================] - 1s 2ms/step - loss: 0.1956 - accuracy: 0.9252 - val_loss: 0.2028 - val_accuracy: 0.9299\n",
      "Epoch 245/300\n",
      "298/298 [==============================] - 1s 3ms/step - loss: 0.1951 - accuracy: 0.9255 - val_loss: 0.2035 - val_accuracy: 0.9283\n",
      "Epoch 246/300\n",
      "298/298 [==============================] - 1s 2ms/step - loss: 0.1948 - accuracy: 0.9238 - val_loss: 0.2040 - val_accuracy: 0.9249\n",
      "Epoch 247/300\n",
      "298/298 [==============================] - 1s 2ms/step - loss: 0.1951 - accuracy: 0.9255 - val_loss: 0.2011 - val_accuracy: 0.9291\n",
      "Epoch 248/300\n",
      "298/298 [==============================] - 1s 3ms/step - loss: 0.1943 - accuracy: 0.9253 - val_loss: 0.2047 - val_accuracy: 0.9270\n",
      "Epoch 249/300\n",
      "298/298 [==============================] - 1s 3ms/step - loss: 0.1952 - accuracy: 0.9252 - val_loss: 0.2010 - val_accuracy: 0.9312\n",
      "Epoch 250/300\n",
      "298/298 [==============================] - 1s 3ms/step - loss: 0.1951 - accuracy: 0.9252 - val_loss: 0.2050 - val_accuracy: 0.9249\n",
      "Epoch 251/300\n",
      "298/298 [==============================] - 1s 2ms/step - loss: 0.1956 - accuracy: 0.9236 - val_loss: 0.2005 - val_accuracy: 0.9308\n",
      "Epoch 252/300\n",
      "298/298 [==============================] - 1s 3ms/step - loss: 0.1954 - accuracy: 0.9237 - val_loss: 0.2009 - val_accuracy: 0.9299\n",
      "Epoch 253/300\n",
      "298/298 [==============================] - 1s 3ms/step - loss: 0.1955 - accuracy: 0.9247 - val_loss: 0.1996 - val_accuracy: 0.9304\n",
      "Epoch 254/300\n",
      "298/298 [==============================] - 1s 3ms/step - loss: 0.1948 - accuracy: 0.9254 - val_loss: 0.2012 - val_accuracy: 0.9299\n",
      "Epoch 255/300\n",
      "298/298 [==============================] - 1s 2ms/step - loss: 0.1949 - accuracy: 0.9242 - val_loss: 0.2041 - val_accuracy: 0.9308\n",
      "Epoch 256/300\n",
      "298/298 [==============================] - 1s 2ms/step - loss: 0.1954 - accuracy: 0.9257 - val_loss: 0.2037 - val_accuracy: 0.9249\n",
      "Epoch 257/300\n",
      "298/298 [==============================] - 1s 2ms/step - loss: 0.1952 - accuracy: 0.9250 - val_loss: 0.2039 - val_accuracy: 0.9279\n",
      "Epoch 258/300\n",
      "298/298 [==============================] - 1s 3ms/step - loss: 0.1954 - accuracy: 0.9237 - val_loss: 0.2022 - val_accuracy: 0.9308\n",
      "Epoch 259/300\n",
      "298/298 [==============================] - 1s 3ms/step - loss: 0.1950 - accuracy: 0.9245 - val_loss: 0.2021 - val_accuracy: 0.9299\n",
      "Epoch 260/300\n",
      "298/298 [==============================] - 1s 3ms/step - loss: 0.1948 - accuracy: 0.9233 - val_loss: 0.2034 - val_accuracy: 0.9308\n",
      "Epoch 261/300\n",
      "298/298 [==============================] - 1s 3ms/step - loss: 0.1949 - accuracy: 0.9239 - val_loss: 0.2018 - val_accuracy: 0.9299\n",
      "Epoch 262/300\n",
      "298/298 [==============================] - 1s 3ms/step - loss: 0.1954 - accuracy: 0.9242 - val_loss: 0.2025 - val_accuracy: 0.9299\n",
      "Epoch 263/300\n",
      "298/298 [==============================] - 1s 3ms/step - loss: 0.1942 - accuracy: 0.9245 - val_loss: 0.2004 - val_accuracy: 0.9299\n",
      "Epoch 264/300\n",
      "298/298 [==============================] - 1s 3ms/step - loss: 0.1950 - accuracy: 0.9248 - val_loss: 0.2015 - val_accuracy: 0.9312\n",
      "Epoch 265/300\n",
      "298/298 [==============================] - 1s 3ms/step - loss: 0.1954 - accuracy: 0.9239 - val_loss: 0.2039 - val_accuracy: 0.9304\n",
      "Epoch 266/300\n",
      "298/298 [==============================] - 1s 3ms/step - loss: 0.1944 - accuracy: 0.9236 - val_loss: 0.1997 - val_accuracy: 0.9291\n",
      "Epoch 267/300\n",
      "298/298 [==============================] - 1s 3ms/step - loss: 0.1951 - accuracy: 0.9252 - val_loss: 0.2004 - val_accuracy: 0.9295\n",
      "Epoch 268/300\n",
      "298/298 [==============================] - 1s 3ms/step - loss: 0.1946 - accuracy: 0.9251 - val_loss: 0.2032 - val_accuracy: 0.9287\n",
      "Epoch 269/300\n",
      "298/298 [==============================] - 1s 2ms/step - loss: 0.1949 - accuracy: 0.9252 - val_loss: 0.2073 - val_accuracy: 0.9308\n",
      "Epoch 270/300\n",
      "298/298 [==============================] - 1s 3ms/step - loss: 0.1949 - accuracy: 0.9251 - val_loss: 0.2002 - val_accuracy: 0.9295\n",
      "Epoch 271/300\n",
      "298/298 [==============================] - 1s 3ms/step - loss: 0.1944 - accuracy: 0.9249 - val_loss: 0.2030 - val_accuracy: 0.9291\n",
      "Epoch 272/300\n",
      "298/298 [==============================] - 1s 3ms/step - loss: 0.1947 - accuracy: 0.9250 - val_loss: 0.2020 - val_accuracy: 0.9299\n",
      "Epoch 273/300\n",
      "298/298 [==============================] - 1s 3ms/step - loss: 0.1947 - accuracy: 0.9246 - val_loss: 0.2014 - val_accuracy: 0.9295\n",
      "Epoch 274/300\n",
      "298/298 [==============================] - 1s 2ms/step - loss: 0.1958 - accuracy: 0.9241 - val_loss: 0.1996 - val_accuracy: 0.9295\n",
      "Epoch 275/300\n",
      "298/298 [==============================] - 1s 3ms/step - loss: 0.1948 - accuracy: 0.9237 - val_loss: 0.2014 - val_accuracy: 0.9308\n",
      "Epoch 276/300\n",
      "298/298 [==============================] - 1s 3ms/step - loss: 0.1945 - accuracy: 0.9258 - val_loss: 0.2090 - val_accuracy: 0.9304\n",
      "Epoch 277/300\n",
      "298/298 [==============================] - 1s 3ms/step - loss: 0.1947 - accuracy: 0.9250 - val_loss: 0.2034 - val_accuracy: 0.9304\n",
      "Epoch 278/300\n",
      "298/298 [==============================] - 1s 3ms/step - loss: 0.1947 - accuracy: 0.9244 - val_loss: 0.2026 - val_accuracy: 0.9312\n",
      "Epoch 279/300\n",
      "298/298 [==============================] - 1s 2ms/step - loss: 0.1948 - accuracy: 0.9253 - val_loss: 0.2020 - val_accuracy: 0.9295\n",
      "Epoch 280/300\n",
      "298/298 [==============================] - 1s 2ms/step - loss: 0.1948 - accuracy: 0.9255 - val_loss: 0.1994 - val_accuracy: 0.9279\n",
      "Epoch 281/300\n",
      "298/298 [==============================] - 1s 2ms/step - loss: 0.1941 - accuracy: 0.9232 - val_loss: 0.2001 - val_accuracy: 0.9287\n",
      "Epoch 282/300\n",
      "298/298 [==============================] - 1s 2ms/step - loss: 0.1943 - accuracy: 0.9253 - val_loss: 0.2018 - val_accuracy: 0.9279\n",
      "Epoch 283/300\n",
      "298/298 [==============================] - 1s 2ms/step - loss: 0.1949 - accuracy: 0.9243 - val_loss: 0.2052 - val_accuracy: 0.9274\n",
      "Epoch 284/300\n",
      "298/298 [==============================] - 1s 2ms/step - loss: 0.1950 - accuracy: 0.9238 - val_loss: 0.2006 - val_accuracy: 0.9308\n",
      "Epoch 285/300\n",
      "298/298 [==============================] - 1s 2ms/step - loss: 0.1948 - accuracy: 0.9235 - val_loss: 0.2044 - val_accuracy: 0.9287\n",
      "Epoch 286/300\n",
      "298/298 [==============================] - 1s 3ms/step - loss: 0.1943 - accuracy: 0.9247 - val_loss: 0.2015 - val_accuracy: 0.9279\n",
      "Epoch 287/300\n",
      "298/298 [==============================] - 1s 2ms/step - loss: 0.1951 - accuracy: 0.9241 - val_loss: 0.1997 - val_accuracy: 0.9299\n",
      "Epoch 288/300\n",
      "298/298 [==============================] - 1s 3ms/step - loss: 0.1949 - accuracy: 0.9244 - val_loss: 0.2003 - val_accuracy: 0.9295\n",
      "Epoch 289/300\n",
      "298/298 [==============================] - 1s 3ms/step - loss: 0.1945 - accuracy: 0.9245 - val_loss: 0.2102 - val_accuracy: 0.9136\n",
      "Epoch 290/300\n",
      "298/298 [==============================] - 1s 3ms/step - loss: 0.1954 - accuracy: 0.9239 - val_loss: 0.2016 - val_accuracy: 0.9295\n",
      "Epoch 291/300\n",
      "298/298 [==============================] - 1s 3ms/step - loss: 0.1945 - accuracy: 0.9242 - val_loss: 0.2024 - val_accuracy: 0.9299\n",
      "Epoch 292/300\n",
      "298/298 [==============================] - 1s 3ms/step - loss: 0.1941 - accuracy: 0.9241 - val_loss: 0.2034 - val_accuracy: 0.9245\n",
      "Epoch 293/300\n",
      "298/298 [==============================] - 1s 3ms/step - loss: 0.1947 - accuracy: 0.9244 - val_loss: 0.2027 - val_accuracy: 0.9316\n",
      "Epoch 294/300\n",
      "298/298 [==============================] - 1s 3ms/step - loss: 0.1955 - accuracy: 0.9248 - val_loss: 0.2018 - val_accuracy: 0.9308\n",
      "Epoch 295/300\n",
      "298/298 [==============================] - 1s 2ms/step - loss: 0.1941 - accuracy: 0.9256 - val_loss: 0.2011 - val_accuracy: 0.9291\n",
      "Epoch 296/300\n",
      "298/298 [==============================] - 1s 2ms/step - loss: 0.1948 - accuracy: 0.9244 - val_loss: 0.1992 - val_accuracy: 0.9291\n",
      "Epoch 297/300\n",
      "298/298 [==============================] - 1s 2ms/step - loss: 0.1952 - accuracy: 0.9250 - val_loss: 0.2015 - val_accuracy: 0.9312\n",
      "Epoch 298/300\n",
      "298/298 [==============================] - 1s 2ms/step - loss: 0.1942 - accuracy: 0.9248 - val_loss: 0.2042 - val_accuracy: 0.9287\n",
      "Epoch 299/300\n",
      "298/298 [==============================] - 1s 3ms/step - loss: 0.1946 - accuracy: 0.9246 - val_loss: 0.2007 - val_accuracy: 0.9287\n",
      "Epoch 300/300\n",
      "298/298 [==============================] - 1s 2ms/step - loss: 0.1943 - accuracy: 0.9238 - val_loss: 0.2014 - val_accuracy: 0.9291\n",
      "WARNING:tensorflow:6 out of the last 166 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000024461DE5090> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "160/160 [==============================] - 0s 1ms/step\n",
      "0.9291307752545027\n"
     ]
    }
   ],
   "source": [
    "## DNN\n",
    "## 1) 불러오기\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.backend import clear_session\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# 메모리 정리\n",
    "clear_session()\n",
    "\n",
    "## 2) 선언하기\n",
    "nfeatures = train_x.shape[1] #num of columns\n",
    "model_DNN = Sequential()\n",
    "\n",
    "# 스케일링\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "train_x = scaler.fit_transform(train_x)\n",
    "test_x =scaler.transform(test_x)\n",
    "\n",
    "# 입력 레이어\n",
    "model_DNN.add(Dense(8,input_shape = (nfeatures,), activation='relu'))\n",
    "# model_DNN.add(Dropout(0.5)) # Dropout은 신경망에서 뉴런의 일부를 무작위로 비활성화하여 과적합을 방지\n",
    "\n",
    "#은닉 레이어\n",
    "model_DNN.add(Dense(6, activation='relu'))\n",
    "# model_DNN.add(Dropout(0.3))\n",
    "\n",
    "# 출력 레이어\n",
    "model_DNN.add(Dense(4, activation='softmax'))\n",
    "\n",
    "## target값 라벨링하기 {'뇌경색':0, '뇌출혈':1, '복부손상':2, '심근경색':3}\n",
    "\n",
    "labeling = {'뇌경색':0, '뇌출혈':1, '복부손상':2, '심근경색':3}\n",
    "\n",
    "train_y_1 = train_y.replace(labeling)\n",
    "test_y_1 = test_y.replace(labeling)\n",
    "## 3) 학습하기\n",
    "\n",
    "model_DNN.compile(optimizer='adam', loss = 'sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "history = model_DNN.fit(train_x,train_y_1, epochs = 300, validation_split = 0.2).history\n",
    "\n",
    "## 4) 예측하기\n",
    "pred_DNN =  model_DNN.predict(test_x)\n",
    "\n",
    "## 5) 평가하기, np.argmax(pred_DNN, axis=1)\n",
    "pred_DNN = np.argmax(pred_DNN, axis=1)\n",
    "\n",
    "print(accuracy_score(test_y_1, pred_DNN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8219f3e6-6a14-4e30-8678-4e0507cac053",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f2582b0a-ffd1-4723-b016-22bc9ee2be58",
   "metadata": {},
   "source": [
    "### 3) 최적 모델 선정 및 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "bf912617-03c2-49c3-a7a1-930652755830",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "딥러닝\n"
     ]
    }
   ],
   "source": [
    "## 질문) 최적 모델로 선정된 것은 무엇인가?\n",
    "print('딥러닝')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "2c86a1f5-41d5-4488-af59-38037270d5cb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## 모델 저장하기\n",
    "\n",
    "#머신러닝 모델인 경우\n",
    "import joblib\n",
    "joblib.dump(model_XGC, '119_model_XGC.pkl')\n",
    "\n",
    "#딥러닝 모델인 경우\n",
    "model_DNN.save('119_model_DNN.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cee7bbf1-aae4-4279-ae4d-892bf6eebd4c",
   "metadata": {},
   "source": [
    "### 4) 새로운 출동 이력 데이터에 대한 중증질환 예측하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "f4d4fcda-662a-44f8-94bb-8667f8bfebd5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 새로운 출동 이력 데이터 : 딕셔너리 형태\n",
    "new_dispatch = {\n",
    "    \"ID\" : [500001],\n",
    "    \"출동일시\" :['2023-04-18'],\n",
    "    \"이름\" : ['최**'],\n",
    "    \"성별\" : [\"여성\"],\n",
    "    \"나이\" : [80],\n",
    "    \"체온\" : [37],\n",
    "    \"수축기 혈압\" : [145],\n",
    "    \"이완기 혈압\" : [100],\n",
    "    \"호흡 곤란\":[0],\n",
    "    \"간헐성 경련\":[1],\n",
    "    \"설사\":[0],\n",
    "    \"기침\":[0],\n",
    "    \"출혈\":[0],\n",
    "    \"통증\":[1],\n",
    "    \"만지면 아프다\":[0],\n",
    "    \"무감각\":[0],\n",
    "    \"마비\":[1],\n",
    "    \"현기증\":[0],\n",
    "    \"졸도\":[1],\n",
    "    \"말이 어눌해졌다\":[1],\n",
    "    \"시력이 흐려짐\":[1],\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "9729913b-84c1-462d-8b49-758998dc2149",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# new_dispatch 딕셔너리를 데이터 프레임으로 변환\n",
    "# 변수명 : new_data\n",
    "new_data = pd.DataFrame(new_dispatch)\n",
    "\n",
    "# new_data를 preprocessing 함수를 이용하여 데이터 전처리하기\n",
    "# 변수명 : new_x\n",
    "new_x = preprocessing(new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "db77def0-da9b-470b-a94e-0e5ea3640209",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>체온</th>\n",
       "      <th>수축기 혈압</th>\n",
       "      <th>이완기 혈압</th>\n",
       "      <th>호흡 곤란</th>\n",
       "      <th>간헐성 경련</th>\n",
       "      <th>설사</th>\n",
       "      <th>기침</th>\n",
       "      <th>출혈</th>\n",
       "      <th>통증</th>\n",
       "      <th>만지면 아프다</th>\n",
       "      <th>무감각</th>\n",
       "      <th>마비</th>\n",
       "      <th>현기증</th>\n",
       "      <th>졸도</th>\n",
       "      <th>말이 어눌해졌다</th>\n",
       "      <th>시력이 흐려짐</th>\n",
       "      <th>발열</th>\n",
       "      <th>고혈압</th>\n",
       "      <th>저혈압</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>37</td>\n",
       "      <td>145</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   체온  수축기 혈압  이완기 혈압  호흡 곤란  간헐성 경련  설사  기침  출혈  통증  만지면 아프다  무감각  마비  현기증  \\\n",
       "0  37     145     100      0       1   0   0   0   1        0    0   1    0   \n",
       "\n",
       "   졸도  말이 어눌해졌다  시력이 흐려짐  발열  고혈압  저혈압  \n",
       "0   1         1        1   1    1    0  "
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "189ed6cd-9586-48f1-8169-b4c967e4e97c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 모델 불러오기\n",
    "\n",
    "# 머신러닝 모델인 경우\n",
    "\n",
    "# import joblib\n",
    "# model_m = \n",
    "\n",
    "# 딥러닝 모델인 경우\n",
    "\n",
    "from keras.models import load_model\n",
    "model_d = load_model('119_model_DNN.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "eaf51602-4431-4d09-8207-355e15a97ef7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 55ms/step\n",
      "예측값 :  [[0.0000000e+00 1.0000000e+00 0.0000000e+00 1.3962613e-36]]\n",
      "인덱스 번호:  [1]\n",
      "예측 중증질환명 :  뇌출혈\n"
     ]
    }
   ],
   "source": [
    "# # 중증질환 예측하기\n",
    "\n",
    "# # 머신러닝 모델인 경우\n",
    "# pred_new_m = \n",
    "# print(\"예측값 : \", pred_new_m)\n",
    "\n",
    "# 딥러닝 모델인 경우\n",
    "pred_new_d = model_d.predict(new_x)\n",
    "print(\"예측값 : \", pred_new_d)\n",
    "\n",
    "\n",
    "# # 중증질환 명칭으로 표시하기\n",
    "\n",
    "sym_list = ['뇌경색', '뇌출혈', '복부손상', '심근경색']\n",
    "\n",
    "# # 머신러닝 모델인 경우\n",
    "# print(\"예측 중증질환명 : \", )\n",
    "\n",
    "# 딥러닝 모델인 경우\n",
    "pred_new_d = np.argmax(pred_new_d, axis=1) # 가장 높은 확률 값을 갖는 클래스의 인덱스를 반환\n",
    "\n",
    "print(\"인덱스 번호: \", pred_new_d)\n",
    "\n",
    "pred_new_d = sym_list[pred_new_d[0]] # 인덱스 번호를 통해서 찾는다.\n",
    "\n",
    "print(\"예측 중증질환명 : \", pred_new_d)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be84e2da",
   "metadata": {},
   "source": [
    "### 5) 새로운 환자(출동 이력)에 대한 중증질환 예측 함수 정의하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b6b2797",
   "metadata": {},
   "source": [
    " * 1. 함수 선언하기\n",
    " * 2. 데이터 준비하기\n",
    " * 3. 중증 질환 예측하기\n",
    " * 4. 중증 질환명으로 반환하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "907ff8c6-9e90-4512-a9ad-1d516b12c5c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 중증질환 예측 함수 정의하기\n",
    "# 함수명 : predict_disease\n",
    "# 매개변수 : new_dispatch (출동 이력 데이터, 딕셔너리 형태)\n",
    "# output : 중증 질환 명칭\n",
    "\n",
    "\n",
    "#########################################\n",
    "# 1. 함수 선언하기                       #\n",
    "#########################################\n",
    "\n",
    "def predict_disease(new_dispatch):\n",
    "    \n",
    "    #########################################\n",
    "    # 2. 데이터 준비하기                     #\n",
    "    #########################################\n",
    "    \n",
    "    # 중증 질환 명칭 및 라벨링 {'뇌경색':0, '뇌출혈':1, '복부손상':2, '심근경색':3}\n",
    "    # 중증 질환 리스트 정의 : 라벨링 순서대로\n",
    "    sym_list = ['뇌경색', '뇌출혈', '복부손상', '심근경색']\n",
    "    \n",
    "    # 딕셔너리 형태의 출동 이력 데이터를 데이터 프레임으로 변환\n",
    "    # 변수명 : new_data\n",
    "\n",
    "    new_data = pd.DataFrame(new_dispatch)\n",
    "\n",
    "    # new_data를 preprocessing 함수를 이용하여 데이터 전처리된 new_x 받아오기\n",
    "    # preporcessing 함수 정의 부분이 먼저 실행되어 있어야 함\n",
    "    \n",
    "    new_x = preprocessing(new_data)\n",
    "\n",
    "    #########################################\n",
    "    # 3. 중증 질환 예측하기                  #\n",
    "    #########################################\n",
    "      \n",
    "#     # 저장된 AI모델 불러오기 \n",
    "#     # 모델 변수명 : model_m\n",
    "\n",
    "#     model_m = \n",
    "\n",
    "    # new_x를 기반으로 중증질환 예측하기\n",
    "    pred_new_m =load_model('119_model_DNN.keras')\n",
    "\n",
    "    #########################################\n",
    "    # 4. 중증 질환명으로 반환하기             #\n",
    "    #########################################\n",
    "\n",
    "    # 예측된 결과를 중증질환 명칭으로 반환하기\n",
    "    \n",
    "    # 딥러닝 모델인 경우\n",
    "    model_d = load_model('119_model_DNN.keras')\n",
    "    \n",
    "    pred_new_d = model_d.predict(new_x)\n",
    "    print(\"예측값 : \", pred_new_d)\n",
    "    \n",
    "    # 딥러닝 모델인 경우\n",
    "    pred_new_d = np.argmax(pred_new_d, axis=1) # 가장 높은 확률 값을 갖는 클래스의 인덱스를 반환\n",
    "\n",
    "    pred_new_d = sym_list[pred_new_d[0]] # 인덱스 번호를 통해서 찾는다.    \n",
    "    \n",
    "    return pred_new_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "63b77824-01b8-45f0-be6e-4bfd8c01bd52",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 46ms/step\n",
      "예측값 :  [[0.0000000e+00 1.0000000e+00 0.0000000e+00 1.3962613e-36]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'뇌출혈'"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 확인하기\n",
    "# predict_disease 함수를 이용하여, 출동 이력 데이터로 중증질환 예측하기\n",
    "\n",
    "new_dispatch = {\n",
    "    \"ID\" : [500001],\n",
    "    \"출동일시\" :['2023-04-18'],\n",
    "    \"이름\" : ['최**'],\n",
    "    \"성별\" : [\"여성\"],\n",
    "    \"나이\" : [80],\n",
    "    \"체온\" : [37],\n",
    "    \"수축기 혈압\" : [145],\n",
    "    \"이완기 혈압\" : [100],\n",
    "    \"호흡 곤란\":[0],\n",
    "    \"간헐성 경련\":[1],\n",
    "    \"설사\":[0],\n",
    "    \"기침\":[0],\n",
    "    \"출혈\":[0],\n",
    "    \"통증\":[1],\n",
    "    \"만지면 아프다\":[0],\n",
    "    \"무감각\":[0],\n",
    "    \"마비\":[1],\n",
    "    \"현기증\":[0],\n",
    "    \"졸도\":[1],\n",
    "    \"말이 어눌해졌다\":[1],\n",
    "    \"시력이 흐려짐\":[1],\n",
    "}\n",
    "\n",
    "\n",
    "predict_disease(new_dispatch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed73a5aa-b2ff-42a3-ac6e-4e9636ba6069",
   "metadata": {},
   "source": [
    "## 미션#3 Clear\n",
    "## 수고하셨습니다!!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "f08154012ddadd8e950e6e9e035c7a7b32c136e7647e9b7c77e02eb723a8bedb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
